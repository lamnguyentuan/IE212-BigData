# ***Cáº¥u trÃºc thÆ° má»¥c trÃªn minIO***

## ğŸŸ« **BRONZE (Raw Layer â€” Dá»¯ liá»‡u thÃ´ nguyÃªn báº£n)**

```
tiktok-data/
â””â”€â”€ bronze/
    â””â”€â”€ {video_id}/
        â”œâ”€â”€ video.mp4
        â””â”€â”€ metadata.json
```

VÃ­ dá»¥:

```
tiktok-data/bronze/7219231231231/video.mp4
tiktok-data/bronze/7219231231231/metadata.json
```

---

## âšª **SILVER (Preprocessed Layer â€” Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ sÆ¡ cáº¥p)**

á» Silver, **váº«n giá»¯ cáº¥u trÃºc theo video_id** Ä‘á»ƒ dá»… trace back toÃ n bá»™ pipeline.

```
tiktok-data/
â””â”€â”€ silver/
    â””â”€â”€ {video_id}/
        â”œâ”€â”€ frames/
        â”‚     â”œâ”€â”€ frame_0001.jpg
        â”‚     â”œâ”€â”€ frame_0002.jpg
        â”‚     â””â”€â”€ ...
        â”‚
        â”œâ”€â”€ audio.wav                     # audio Ä‘Ã£ chuáº©n hoÃ¡ 16 kHz
        â”‚
        â”œâ”€â”€ caption.txt                   # caption Ä‘Ã£ cleaned
        â”œâ”€â”€ comments.txt                  # comments Ä‘Ã£ cleaned
        â”œâ”€â”€ merged_text.txt               # caption + comments
        â”‚
        â””â”€â”€ clean_metadata.json           # metadata Ä‘Ã£ chuáº©n hoÃ¡
```

VÃ­ dá»¥:

```
tiktok-data/silver/7219231231231/frames/frame_0001.jpg
tiktok-data/silver/7219231231231/audio.wav
tiktok-data/silver/7219231231231/merged_text.txt
```

---

## ğŸŸ¡ **GOLD (Feature Layer â€” Dá»¯ liá»‡u Ä‘Ã£ trÃ­ch embedding)**

Váº«n theo tá»«ng video_id, nhÆ°ng chia file theo modality:

```
tiktok-data/
â””â”€â”€ gold/
    â””â”€â”€ {video_id}/
        â”œâ”€â”€ video_embedding.npy
        â”œâ”€â”€ audio_embedding.npy
        â”œâ”€â”€ text_embedding.npy
        â”œâ”€â”€ fused_embedding.npy           # concat(video + audio + text)
        â”‚
        â””â”€â”€ label.json                    # Safe / Not Safe
```

VÃ­ dá»¥:

```
tiktok-data/gold/7219231231231/video_embedding.npy
tiktok-data/gold/7219231231231/fused_embedding.npy
tiktok-data/gold/7219231231231/label.json
```

---

# ğŸ¯ **TÃ³m táº¯t Ä‘áº§y Ä‘á»§ cáº¥u trÃºc MinIO theo yÃªu cáº§u**

```
tiktok-data/
â”œâ”€â”€ bronze/
â”‚    â””â”€â”€ {video_id}/
â”‚         â”œâ”€â”€ video.mp4
â”‚         â””â”€â”€ metadata.json
â”‚
â”œâ”€â”€ silver/
â”‚    â””â”€â”€ {video_id}/
â”‚         â”œâ”€â”€ frames/
â”‚         â”‚     â”œâ”€â”€ frame_0001.jpg
â”‚         â”‚     â””â”€â”€ ...
â”‚         â”œâ”€â”€ audio.wav
â”‚         â”œâ”€â”€ caption.txt
â”‚         â”œâ”€â”€ comments.txt
â”‚         â”œâ”€â”€ merged_text.txt
â”‚         â””â”€â”€ clean_metadata.json
â”‚
â””â”€â”€ gold/
     â””â”€â”€ {video_id}/
          â”œâ”€â”€ video_embedding.npy
          â”œâ”€â”€ audio_embedding.npy
          â”œâ”€â”€ text_embedding.npy
          â”œâ”€â”€ fused_embedding.npy
          â””â”€â”€ label.json
```

# ***Cáº¥u trÃºc thÆ° má»¥c data processing***

ThÆ° má»¥c `offline-training/preprocessing/` chá»©a toÃ n bá»™ code tiá»n xá»­ lÃ½ dá»¯ liá»‡u Ä‘á»ƒ chuáº©n bá»‹ cho bÆ°á»›c **offline training mÃ´ hÃ¬nh Ä‘a phÆ°Æ¡ng thá»©c (video + audio + text + metadata)** trong dá»± Ã¡n TikHarm.

Má»¥c tiÃªu chÃ­nh:

- Chuáº©n hoÃ¡ metadata TikTok (likes, comments, shares, hashtags, date, â€¦)
- Chuáº©n hoÃ¡ vÄƒn báº£n báº±ng **ViNormT5**
- PhÃ¡t hiá»‡n **Toxicity** vÃ  **Constructiveness** trong comment tree
- Sinh **text embeddings** (Phobert) cho description, tags, comments
- TrÃ­ch xuáº¥t **video features** (frame / clip embedding)
- TrÃ­ch xuáº¥t **audio features** (wav2vec, â€¦)
- Káº¿t há»£p táº¥t cáº£ thÃ nh **multimodal feature** lÆ°u ra Silver/Gold layer (Parquet/JSON/NPY/MinIO)

---

## ğŸ—‚ Cáº¥u trÃºc thÆ° má»¥c

```text
offline-training/
â””â”€â”€ preprocessing/
    â”œâ”€â”€ metadata/
    â”œâ”€â”€ video/
    â”œâ”€â”€ audio/
    â”œâ”€â”€ text/
    â”œâ”€â”€ features/
    â”œâ”€â”€ utils/
    â”œâ”€â”€ pipelines/
    â””â”€â”€ notebooks/
```

---

## 1ï¸âƒ£ `metadata/` â€” Xá»­ lÃ½ metadata TikTok

> CÃ¡c file nÃ y chá»‹u trÃ¡ch nhiá»‡m Ä‘á»c JSON metadata (nhÆ° vÃ­ dá»¥ báº¡n Ä‘Æ°a), chuáº©n hoÃ¡ sá»‘, text, comment, vÃ  sinh metadata embedding.

**Cáº¥u trÃºc (dá»± kiáº¿n):**

```text
metadata/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ metadata_preprocessor.py      # class MetadataPreprocessor (dÃ¹ng ViNormT5 + Phobert + Toxic/Constructive)
â”œâ”€â”€ numeric_features.py           # parse K/M, log1p, ratio, date encoding
â”œâ”€â”€ text_normalizer.py            # wrapper model meoo225/ViNormT5
â”œâ”€â”€ toxicity_classifier.py        # wrapper funa21/phobert-finetuned-victsd-toxic-v2
â”œâ”€â”€ constructive_classifier.py    # wrapper funa21/phobert-finetuned-victsd-constructiveness-v2
â”œâ”€â”€ text_embeddings.py            # Phobert-base embedding cho desc/tags/comments
â”œâ”€â”€ comments_processing.py        # flatten comments_tree, basic stats
â””â”€â”€ metadata_schema.py            # optional: validate/normalize input JSON
```

**Main entry:**

* `MetadataPreprocessor` trong `metadata_preprocessor.py`:

  * Chuáº©n hoÃ¡ cÃ¡c trÆ°á»ng sá»‘: likes, comments, shares, bookmarks, views
  * Táº¡o cÃ¡c feature tá»‰ lá»‡: like_rate, engagement_rate, â€¦
  * Date â†’ `age_days`, `month_sin`, `month_cos`
  * Chuáº©n hoÃ¡ text (description, tags, comments) báº±ng **ViNormT5**
  * Map emoji â†’ token (`<EMOJI_LAUGH>`, â€¦)
  * Flatten `comments_tree`, tÃ­nh:

    * sá»‘ comment, avg length, pháº§n trÄƒm cmt cÃ³ emoji cÆ°á»i, cÃ³ dáº¥u há»i
    * sá»‘ lÆ°á»£ng & tá»‰ lá»‡ **toxic comments**
    * sá»‘ lÆ°á»£ng & tá»‰ lá»‡ **constructive comments**
  * Encode description, tags, comments báº±ng Phobert â†’ embedding
  * Log + scale numeric feature (StandardScaler)
  * Tráº£ vá»:

    * `numeric_scaled`, `numeric_raw`
    * `desc_emb`, `tags_emb`, `comments_emb`

---

## 2ï¸âƒ£ `video/` â€” Xá»­ lÃ½ video

> Chá»‹u trÃ¡ch nhiá»‡m load video, trÃ­ch xuáº¥t frame, vÃ  (sau nÃ y) táº¡o video embedding.

**Cáº¥u trÃºc gá»£i Ã½:**

```text
video/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ video_loader.py               # Ä‘á»c video tá»« local hoáº·c MinIO
â”œâ”€â”€ video_frame_extractor.py      # ffmpeg/decord/pyav â†’ frames
â”œâ”€â”€ video_encoder_timesformer.py  # (sau nÃ y) TimeSformer/ViViT embedding
â””â”€â”€ video_utils.py                # helper: resize, clip, fps, etc.
```

Output mong muá»‘n:

* Táº­p frame/clip (Ä‘á»ƒ debug)
* Hoáº·c vector `video_emb` (np.ndarray / torch.Tensor) cho má»—i video ID

---

## 3ï¸âƒ£ `audio/` â€” Xá»­ lÃ½ audio tá»« video

> Extract audio track, chuáº©n hoÃ¡, sinh audio embedding.

**Cáº¥u trÃºc gá»£i Ã½:**

```text
audio/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ audio_extractor.py            # ffmpeg: .mp4 â†’ .wav
â”œâ”€â”€ audio_encoder_wav2vec.py      # wav2vec2 / hubert / XLSR embedding
â””â”€â”€ audio_utils.py                # resample, mono, chunk, etc.
```

Output:

* File `.wav` / `.flac` trung gian (tuá»³ báº¡n)
* Vector `audio_emb` (per video)

---

## 4ï¸âƒ£ `text/` â€” OCR / ASR / text cleaning

> DÃ¹ng náº¿u báº¡n trÃ­ch text tá»« video (subtitles, speech, text overlay).

**Cáº¥u trÃºc gá»£i Ã½:**

```text
text/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ ocr_processor.py              # OCR trÃªn frame / thumbnail
â”œâ”€â”€ asr_processor.py              # speech-to-text
â””â”€â”€ text_cleaner.py               # regex cleaning, lowercasing, remove html, etc.
```

Output:

* Chuá»—i text (ASR/OCR) gáº¯n vá»›i video_id
* CÃ³ thá»ƒ Ä‘Æ°a vÃ o Phobert encoder (reuse code tá»« `metadata/text_embeddings.py`)

---

## 5ï¸âƒ£ `features/` â€” Build & Save multimodal features

```text
features/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ multimodal_feature_builder.py # ghÃ©p video_emb + audio_emb + metadata_emb + text_emb
â”œâ”€â”€ feature_saver.py              # lÆ°u ra parquet / JSON / NPY / MinIO
â””â”€â”€ feature_schema.py             # schema cho 1 sample multimodal
```

* `multimodal_feature_builder.py`:

  * Nháº­n input tá»« cÃ¡c pipeline:

    * `metadata_preprocessor` â†’ numeric + desc/tags/comments emb
    * `video_encoder` â†’ video_emb
    * `audio_encoder` â†’ audio_emb
    * (optional) OCR/ASR emb
  * Gá»™p láº¡i (concat / projection / pooling) â†’ `multimodal_feature`

* `feature_saver.py`:

  * LÆ°u má»—i sample hoáº·c batch ra:

    * Local: `.jsonl`, `.parquet`, `.npy`, `.pt`
    * MinIO: theo layout Medallion: `silver/` hoáº·c `gold/`

---

## 6ï¸âƒ£ `utils/` â€” Helper chung

```text
utils/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ file_io.py                    # Ä‘á»c/ghi JSON, CSV, parquet, NPY
â”œâ”€â”€ minio_utils.py                # client káº¿t ná»‘i MinIO (list, get, put)
â”œâ”€â”€ logging_utils.py              # logger thá»‘ng nháº¥t cho pipeline
â”œâ”€â”€ timer.py                      # context manager Ä‘o thá»i gian
â””â”€â”€ constants.py                  # Ä‘Æ°á»ng dáº«n, tÃªn bucket, key chuáº©n
```

VÃ­ dá»¥ patterns:

* `file_io.py`:

  * `load_json(path)`, `save_json(obj, path)`, `save_parquet(df, path)`, â€¦

* `minio_utils.py`:

  * `get_minio_client()`, `download_from_minio(bucket, key, local_path)`, â€¦

---

## 7ï¸âƒ£ `pipelines/` â€” Orchestrate tá»«ng bÆ°á»›c

```text
pipelines/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ preprocess_metadata_pipeline.py   # cháº¡y MetadataPreprocessor cho list video
â”œâ”€â”€ preprocess_video_pipeline.py      # xá»­ lÃ½ toÃ n bá»™ video â†’ video_emb
â”œâ”€â”€ preprocess_audio_pipeline.py      # xá»­ lÃ½ toÃ n bá»™ video â†’ audio_emb
â””â”€â”€ build_multimodal_dataset.py       # join táº¥t cáº£ feature láº¡i thÃ nh dataset training
```

### `preprocess_metadata_pipeline.py`

* Äá»c file manifest (danh sÃ¡ch video + Ä‘Æ°á»ng dáº«n metadata JSON)
* Vá»›i má»—i video:

  * Load metadata JSON
  * Gá»i `MetadataPreprocessor.transform_single(meta)`
  * LÆ°u káº¿t quáº£: numeric_scaled + embeddings vÃ o Silver layer

### `preprocess_video_pipeline.py`

* Äá»c danh sÃ¡ch video_s3_path / local_path
* Extract frames / clip, encode â†’ `video_emb`
* LÆ°u embedding (theo video_id)

### `preprocess_audio_pipeline.py`

* Extract audio tá»« video
* Encode â†’ `audio_emb`
* LÆ°u embedding (theo video_id)

### `build_multimodal_dataset.py`

* Join metadata_emb + video_emb + audio_emb (+ OCR/ASR náº¿u cÃ³) theo `video_id`
* Táº¡o final dataset (Parquet/JSONL) Ä‘á»ƒ model training Ä‘á»c vÃ o.

---

## 8ï¸âƒ£ `notebooks/` â€” Debug & EDA

```text
notebooks/
â”œâ”€â”€ debug_metadata.ipynb      # test MetadataPreprocessor trÃªn vÃ i JSON máº«u
â”œâ”€â”€ debug_comments.ipynb      # visualize toxicity / constructiveness trong comment
â”œâ”€â”€ test_video_embedding.ipynb# test video encoder trÃªn 1â€“2 video
â””â”€â”€ EDA_metadata.ipynb        # EDA phÃ¢n phá»‘i likes, shares, age_days, ...
```

DÃ¹ng Ä‘á»ƒ:

* Kiá»ƒm tra xem feature Ä‘Ã£ há»£p lÃ½ chÆ°a
* Váº½ histogram / scatter / PCA trÃªn embedding
* Debug nhanh mÃ  khÃ´ng cáº§n cháº¡y full pipeline

---

## ğŸ”„ Luá»“ng cháº¡y cÆ¡ báº£n

1. Chuáº©n bá»‹ danh sÃ¡ch video (manifest) chá»©a:

   * `video_id`
   * `metadata_path` (JSON)
   * `video_s3_path` hoáº·c `video_local_path`

2. Cháº¡y tá»«ng pipeline:

```bash
# 1) Metadata
python offline-training/preprocessing/pipelines/preprocess_metadata_pipeline.py

# 2) Video
python offline-training/preprocessing/pipelines/preprocess_video_pipeline.py

# 3) Audio
python offline-training/preprocessing/pipelines/preprocess_audio_pipeline.py

# 4) Build multimodal dataset (join táº¥t cáº£ láº¡i)
python offline-training/preprocessing/pipelines/build_multimodal_dataset.py
```

3. Output cuá»‘i:

   * Má»™t file/bá»™ file Parquet/JSONL trong `offline-training/datasets/` hoáº·c MinIO `tikharm/silver` / `tikharm/gold`
   * DÃ¹ng trá»±c tiáº¿p cho `training/` (DataLoader + Trainer).
