version: '3.8'

services:
  # -----------------------------------
  # 1. Infrastructure Layer
  # -----------------------------------

  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

  minio:
    image: minio/minio
    container_name: minio
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=12345678
    ports:
      - "9000:9000" # API
      - "9001:9001" # Console Web UI
    command: server /data --console-address ":9001"
    volumes:
      - ./minio-data:/data

  mongodb:
    image: mongo:6.0
    container_name: mongodb
    ports:
      - "27017:27017"
    volumes:
      - ./mongo-data:/data/db

  # -----------------------------------
  # 2. Processing Layer (Spark)
  # -----------------------------------

  spark-master:
    image: bitnami/spark:3.5.0
    container_name: spark-master
    environment:
      - SPARK_MODE=master
    ports:
      - "8080:8080"
      - "7077:7077"

  spark-worker:
    image: bitnami/spark:3.5.0
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - spark-master

  # -----------------------------------
  # 3. Application Layer
  # -----------------------------------

  model-serving:
    build:
      context: .
      dockerfile: model-serving/Dockerfile
    container_name: model-serving
    ports:
      - "8000:8000"
    environment:
      - MINIO_ENDPOINT=valuable-usgs-miles-diy.trycloudflare.com
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=12345678
    depends_on:
      - minio

  dashboard:
    image: python:3.9-slim
    container_name: dashboard
    working_dir: /app
    volumes:
      - .:/app
    command: streamlit run dashboard/app.py --server.address=0.0.0.0 --server.port=8501
    ports:
      - "8501:8501"
    environment:
      - MONGO_URI=mongodb://mongodb:27017/
      - MINIO_ENDPOINT=valuable-usgs-miles-diy.trycloudflare.com
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=12345678
    depends_on:
      - mongodb
      - minio

  # -----------------------------------
  # 4. Orchestration (Airflow - Simplified)
  # -----------------------------------
  # Using a simple standalone airflow for demo purposes
  airflow:
    image: apache/airflow:2.7.1
    container_name: airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=sqlite:////root/airflow/airflow.db
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
      - ./deployment/airflow/dags:/opt/airflow/dags
    ports:
      - "8081:8080"
    command: bash -c "airflow db init && airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com && airflow webserver --port 8080 -D && airflow scheduler"
