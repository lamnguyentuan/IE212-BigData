# ğŸ¥ TikTok Harmfulness Detection System (Real-time Big Data Pipeline)

**Há»‡ thá»‘ng PhÃ¢n tÃ­ch & PhÃ¡t hiá»‡n Ná»™i dung Äá»™c háº¡i trÃªn TikTok theo Thá»i gian thá»±c**

![Badge](https://img.shields.io/badge/Status-Active-success)
![Docker](https://img.shields.io/badge/Docker-Enabled-blue)
![Spark](https://img.shields.io/badge/Apache%20Spark-Streaming-orange)

Äá»“ Ã¡n mÃ´n há»c **IE212 - Big Data**, táº­p trung xÃ¢y dá»±ng má»™t há»‡ thá»‘ng xá»­ lÃ½ dá»¯ liá»‡u lá»›n Ä‘a phÆ°Æ¡ng thá»©c (Video, Audio, Metadata) End-to-End tá»« khÃ¢u thu tháº­p Ä‘áº¿n hiá»ƒn thá»‹ cáº£nh bÃ¡o.

---

## ğŸ—ï¸ Kiáº¿n trÃºc Há»‡ thá»‘ng (System Architecture)

Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ theo mÃ´ hÃ¬nh **Lambda Architecture** (táº­p trung vÃ o Speed Layer cho Real-time Demo), bao gá»“m cÃ¡c thÃ nh pháº§n chÃ­nh:

1.  **Ingestion Layer (Thu tháº­p)**
    *   **Crawler (Playwright + Python)**: Tá»± Ä‘á»™ng tÆ°Æ¡ng tÃ¡c vá»›i TikTok Web, táº£i video `.mp4`, trÃ­ch xuáº¥t metadata (comment, view, like).
    *   **Apache Kafka**: Message Broker chá»‹u táº£i cao, nháº­n sá»± kiá»‡n tá»« Crawler vÃ  phÃ¢n phá»‘i Ä‘áº¿n bá»™ xá»­ lÃ½.

2.  **Storage Layer (LÆ°u trá»¯)**
    *   **MinIO (Data Lake)**: LÆ°u trá»¯ dá»¯ liá»‡u phi cáº¥u trÃºc (Unstructured Data) nhÆ° Video, Audio, Features.
    *   **MongoDB (NoSQL)**: LÆ°u trá»¯ dá»¯ liá»‡u cáº¥u trÃºc (Structured Data) nhÆ° káº¿t quáº£ dá»± Ä‘oÃ¡n, metadata, logs.

3.  **Processing Layer (Xá»­ lÃ½)**
    *   **Apache Spark Structured Streaming**: Xá»­ lÃ½ dá»¯ liá»‡u thá»i gian thá»±c tá»« Kafka.
    *   **Multimodal Inference**:
        *   **Video**: TrÃ­ch xuáº¥t Frames -> TimeSformer Model.
        *   **Audio**: TrÃ­ch xuáº¥t Audio -> Wav2Vec2 Model.
        *   **Fusion**: Káº¿t há»£p Ä‘áº·c trÆ°ng Ä‘á»ƒ phÃ¢n loáº¡i `Safe` vs `Harmful`.
    *   **Model Serving API**: Microservice (FastAPI+Uvicorn) cung cáº¥p kháº£ nÄƒng Inference Ä‘á»™c láº­p.

4.  **Orchestration Layer (Äiá»u phá»‘i)**
    *   **Apache Airflow**: Láº­p lá»‹ch tá»± Ä‘á»™ng (Schedule) cho viá»‡c Crawling Ä‘á»‹nh ká»³ hoáº·c Retrain model.

5.  **Presentation Layer (Hiá»ƒn thá»‹)**
    *   **Streamlit Dashboard**: Giao diá»‡n ngÆ°á»i dÃ¹ng theo dÃµi Real-time, phÃ¡t láº¡i video, hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ thá»‘ng kÃª.

---

## ğŸ› ï¸ YÃªu cáº§u CÃ i Ä‘áº·t (Prerequisites)

*   **Docker & Docker Compose** (Báº¯t buá»™c)
*   **Python 3.9+** (Náº¿u cháº¡y script client)
*   RAM: Tá»‘i thiá»ƒu 8GB (Khuyáº¿n nghá»‹ 16GB do cháº¡y Spark & DL Models)

---

## ğŸš€ HÆ°á»›ng dáº«n Cháº¡y (Quick Start)

### 1. Khá»Ÿi Ä‘á»™ng Háº¡ táº§ng (Infrastructure)

Táº¡i thÆ° má»¥c gá»‘c cá»§a dá»± Ã¡n:

```bash
# Build images vÃ  khá»Ÿi cháº¡y services (Airflow, Spark, Kafka, MinIO, Dashboard...)
docker-compose up -d --build
```

Äá»£i khoáº£ng 2-5 phÃºt Ä‘á»ƒ cÃ¡c image Ä‘Æ°á»£c build vÃ  services khá»Ÿi Ä‘á»™ng hoÃ n táº¥t.

### 2. Truy cáº­p Giao diá»‡n Quáº£n lÃ½

Náº¿u cháº¡y trÃªn mÃ¡y cá»¥c bá»™ (Localhost):

*   **Airflow**: [http://localhost:8081](http://localhost:8081) (Admin: `admin`/`admin`)
*   **Dashboard**: [http://localhost:8501](http://localhost:8501)
*   **Spark Master**: [http://localhost:8080](http://localhost:8080)
*   **MinIO Console**: [http://localhost:9001](http://localhost:9001) (User: `minioadmin`/`minioadmin`)

*(Náº¿u cháº¡y trÃªn Server/VPS, hÃ£y sá»­ dá»¥ng SSH Tunnel Ä‘á»ƒ forward cÃ¡c port nÃ y vá» mÃ¡y cÃ¡ nhÃ¢n).*

### 3. Demo Ká»‹ch báº£n End-to-End

Äá»ƒ tháº¥y dá»¯ liá»‡u cháº¡y tá»« Crawler -> Dashboard, hÃ£y lÃ m theo cÃ¡c bÆ°á»›c sau:

#### BÆ°á»›c 1: Thu tháº­p Dá»¯ liá»‡u (Trigger Crawl)
VÃ o **Airflow UI** -> KÃ­ch hoáº¡t DAG `tiktok_crawl_pipeline`.
*hoáº·c cháº¡y thá»§ cÃ´ng trong container:*
```bash
docker exec crawler python data_pipeline/crawl_only.py review
```

#### BÆ°á»›c 2: Giáº£ láº­p Luá»“ng dá»¯ liá»‡u (Producer)
Script nÃ y sáº½ quÃ©t MinIO vÃ  gá»­i thÃ´ng bÃ¡o "New Video" tá»›i Kafka.
```bash
# Cáº§n cÃ i venv á»Ÿ mÃ¡y host Ä‘á»ƒ cháº¡y script nÃ y
export MINIO_ENDPOINT="localhost:9009"
export MINIO_ACCESS_KEY="minioadmin"
export MINIO_SECRET_KEY="minioadmin"

python data_pipeline/producer_simulator.py
```

#### BÆ°á»›c 3: Xá»­ lÃ½ & Dá»± Ä‘oÃ¡n (Spark Streaming)
Khá»Ÿi cháº¡y Spark Job Ä‘á»ƒ láº¯ng nghe Kafka vÃ  gá»i Model AI.
```bash
export MINIO_ENDPOINT="localhost:9009"
export MINIO_ACCESS_KEY="minioadmin"
export MINIO_SECRET_KEY="minioadmin"
export MONGO_URI="mongodb://localhost:27017/"

python data_pipeline/spark-streaming/main_stream.py --mode stream
```

**Káº¿t quáº£:** Má»Ÿ Dashboard táº¡i `localhost:8501`, báº¡n sáº½ tháº¥y cÃ¡c video má»›i xuáº¥t hiá»‡n liÃªn tá»¥c cÃ¹ng nhÃ£n dá»± Ä‘oÃ¡n (Harmful/Safe)!

---

## ğŸ“‚ Cáº¥u trÃºc Dá»± Ã¡n

```
.
â”œâ”€â”€ airflow/                 # Cáº¥u hÃ¬nh & DAGs cho Airflow
â”œâ”€â”€ common/                  # Modules dÃ¹ng chung (MinIO client, Features utils)
â”œâ”€â”€ dashboard/               # MÃ£ nguá»“n Streamlit Dashboard (Dockerfile riÃªng)
â”œâ”€â”€ data_pipeline/           # CÃ¡c script xá»­ lÃ½ dá»¯ liá»‡u chÃ­nh
â”‚   â”œâ”€â”€ producer_simulator.py  # Giáº£ láº­p Kafka Producer
â”‚   â”œâ”€â”€ crawl_only.py          # Script Crawl gá»n nháº¹
â”‚   â””â”€â”€ spark-streaming/       # PySpark Streaming Job
â”œâ”€â”€ demo-crawl.Dockerfile    # Dockerfile cho Crawler Service
â”œâ”€â”€ docker-compose.yml       # File Ä‘á»‹nh nghÄ©a toÃ n bá»™ háº¡ táº§ng Docker
â”œâ”€â”€ model-serving/           # API Server cho AI Model (FastAPI)
â”œâ”€â”€ offline_training/        # Quy trÃ¬nh huáº¥n luyá»‡n Model (Preprocessing)
â””â”€â”€ requirements.txt         # CÃ¡c thÆ° viá»‡n phá»¥ thuá»™c
```

---

## ğŸ‘¨â€ğŸ’» TÃ¡c giáº£

Äá»“ Ã¡n Ä‘Æ°á»£c thá»±c hiá»‡n bá»Ÿi nhÃ³m sinh viÃªn **IE212 - UIT**.
Má»i gÃ³p Ã½ xin gá»­i vá» [Issues](https://github.com/your-repo/issues).
